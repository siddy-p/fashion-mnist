# Model Compression with TensorFlow/Keras: Pruning & Quantization

This repo contains two Jupyter notebooks showing endâ€‘toâ€‘end **model compression** on classic vision datasets using **TensorFlow/Keras** and the **TensorFlow Model Optimization Toolkit (TFMOT)**:

- **`Pruning_24192929.ipynb`** â€“ Structured workflow for pruning a Keras model, measuring sparsity and accuracy, and exporting the pruned model.
- **`Quantization_24192929.ipynb`** â€“ Quantization workflows including **Quantizationâ€‘Aware Training (QAT)** and TFâ€‘Lite conversion to **INT8** (fullâ€‘integer). Produces a deployable `.tflite` file.

---

## ğŸ§± Whatâ€™s inside

```
.
â”œâ”€â”€ Pruning_24192929.ipynb
â”œâ”€â”€ Quantization_24192929.ipynb
â””â”€â”€ models/
    â””â”€â”€ new_model_full_integer_quant.tflite   # generated by the quantization notebook
```

> **Datasets used in the notebooks:** `MNIST` (and in places `Fashionâ€‘MNIST`). These are downloaded automatically via `tf.keras.datasets`â€”no manual download needed.

---

## âœ… Verified environment (from notebooks)

- **Python:** 3.12
- **Kernels:** `cpu_env`, `conda-base-py`
- **Frameworks imported:** `tensorflow`, `keras / tf_keras`, `tensorflow_model_optimization (tfmot)`, `scikitâ€‘learn`
- **Common libs:** `numpy`, `matplotlib`, `pandas`
- **Hardware:** runs on CPU; GPU/CUDA is optional (notebooks detect/use it when available).

---

## ğŸ“¦ Installation

Create a fresh environment (recommended), then install dependencies:

```bash
pip install   "tensorflow>=2.12"   tensorflow-model-optimization   numpy matplotlib pandas scikit-learn
```

> If youâ€™re on Keras 3 and see `tf_keras` imports, install the compatibility layer:
>
> ```bash
> pip install keras==3.* keras-core
> ```

---

## â–¶ï¸ How to run

1. **Clone** your repository and **enter** it:
   ```bash
   git clone <YOUR_REPO_URL>.git
   cd <YOUR_REPO_DIR>
   ```

2. **(Optional) Create env** and install packages (see above).

3. **Launch Jupyter** and open either notebook:
   ```bash
   jupyter notebook
   ```

4. **Run all cells** in:
   - `Pruning_24192929.ipynb` â€“ pruning workflow
   - `Quantization_24192929.ipynb` â€“ QAT + TFâ€‘Lite INT8 conversion

> The quantization notebook writes a TFâ€‘Lite model to:
>
> `./models/new_model_full_integer_quant.tflite`

---

## ğŸ§ª Notebook details

### 1) Pruning (`Pruning_24192929.ipynb`)

**Main steps (as implemented in the notebook):**
- Load and preprocess **MNIST / Fashionâ€‘MNIST** with `tf.keras.datasets`.
- Build and train a baseline **Keras** model.
- Evaluate baseline **accuracy**.
- Configure pruning using **TFMOT** (`tfmot.sparsity.keras`): define pruning schedule and callbacks.
- **Apply pruning**, train/fineâ€‘tune, and **measure sparsity** / size effects.
- (Typical) Strip pruning wrappers and **export** the final pruned model/artifacts.

**Key libraries used:** `tensorflow`, `keras (tf_keras)`, `tensorflow_model_optimization`, `numpy`, `matplotlib`, `pandas`, `scikitâ€‘learn`.

**Metrics tracked:** accuracy, sparsity/size (and optionally precision if computed).


### 2) Quantization (`Quantization_24192929.ipynb`)

**Main steps (as implemented in the notebook):**
- Load and preprocess **MNIST**.
- Train or load a floatingâ€‘point Keras model.
- Configure **QAT** using **TFMOT** (`tfmot.quantization.keras`).
- Fineâ€‘tune the QAT model and evaluate **accuracy**.
- **Convert to TFâ€‘Lite** with **fullâ€‘integer (INT8)** quantization (with calibration dataset where needed).
- **Export**: `models/new_model_full_integer_quant.tflite`.
- (Optional) Evaluate the TFâ€‘Lite model accuracy via an interpreter loop.

**Key libraries used:** `tensorflow`, `tensorflow_model_optimization`, `numpy`, `matplotlib`.

**Metrics tracked:** accuracy, model size (before/after), and (optionally) precision.


---

## ğŸ“Š Record your results

Use this table to track your outcomes (fill in after running the notebooks):

| Experiment | Dataset        | Baseline Acc. | Compressed Acc. | Size (MB) Before | Size (MB) After | Notes |
|-----------:|----------------|---------------:|-----------------:|------------------:|----------------:|-------|
| Pruning    | MNIST / Fâ€‘MNIST|                |                  |                   |                 |       |
| QAT (INT8) | MNIST          |                |                  |                   |                 |       |

---

## ğŸ’¡ Tips

- For reproducible training, set random seeds (`tf.random.set_seed`, `np.random.seed`).
- Start with moderate pruning sparsity, then increase gradually to limit accuracy drop.
- For **INT8** conversion quality, ensure representative samples for calibration and (ideally) a few more fineâ€‘tuning epochs during QAT.
- Test the `.tflite` model on the target device to verify latency and accuracy.

---

## ğŸ“ License

MIT â€” feel free to use and adapt.
